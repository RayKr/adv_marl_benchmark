experimentName: nni-optimizer-lr
searchSpace:
  # common hyperparameters [don't change]
  algo_args.train.log_dir:
    _type: choice
    _value: ["#nni_dynamic"]
  # end common hyperparameters
  
  algo_args.train.num_env_steps:
    _type: choice
    _value: [3000000]
  main_args.algo:
    _type: choice
    _value: ["mappo", "maddpg", "qmix"]
  main_args.env:
    _type: choice
    _value: ["smac"]
  main_args.run:
    _type: choice
    _value: [
        "single",
        # 'perturbation',
        # "traitor",
      ]
  env_args.map_name:
    _type: choice
    _value: ["3m", "3s_vs_5z", "4m_vs_3m", "4s_vs_5z"]
  algo_args.train.seed:
    _type: choice
    _value: [0, 1]

  # multi-agent training
  algo_args.train.share_param:
    _type: choice
    _value: [true, false]
  algo_args.train.algo_type:
    _type: choice
    _value: ["IL", "VD", "CC"]

trialCommand: python -u ../../single_train.py --env smac --algo mappo --exp_name nni-optimizer-lr --run single
trialCodeDirectory: .
trialGpuNumber: 1
trialConcurrency: 3
tuner:
  name: GridSearch
trainingService:
  platform: local
  useActiveGpu: True
  maxTrialNumberPerGpu: 5
  gpuIndices: [0]
